{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Create your ABox\n",
    "\n",
    "Now that we have an ontology, let's instantiate it and create a range of instances that represents a space that has several elements of different types, with names. We will hereby follow the same UML Class diagram and our `MFI` ontology created in the previous step. This will result in an RDF graph or an ABox model (Assertion Box).\n",
    "\n",
    "- `MFI`: https://example.org/myFirstOntology#\n",
    "- `INST`: https://example.org/myFirstInstanceGraph#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create initial Graph in RDFLib\n",
    "We now setup again `rdflib` and our initial graph with the needed prefixes and namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N35a4bcc94cdb4a379976506b3995a230 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import needed components from rdflib\n",
    "from rdflib import Graph , Literal , BNode , Namespace , RDF , RDFS , OWL , URIRef\n",
    "\n",
    "# initiate triple store, i.e. Graph()\n",
    "g = Graph()\n",
    "\n",
    "# Add namespaces and prefixes for ontologies\n",
    "g.bind(\"owl\", OWL)\n",
    "MFI = Namespace(\"https://example.org/myFirstOntology#\")\n",
    "g.bind(\"mfi\", MFI)\n",
    "\n",
    "# Add namespace and prefix for instance graph (ABox)\n",
    "INST = Namespace(\"https://example.org/myFirstInstanceGraph#\")\n",
    "g.bind(\"\", INST) # bind to default empty prefix\n",
    "g.bind(\"inst\", INST) # bind to inst prefix\n",
    "\n",
    "# Initiate ontology entity\n",
    "s = URIRef(\"https://example.org/myFirstInstanceGraph\")\n",
    "p = RDF.type\n",
    "o = OWL.Ontology\n",
    "g.add((s, p, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding Spaces and Elements\n",
    "We will now add instances in our graph. Let's try to create the following instances:\n",
    "- 3 spaces\n",
    "- 1 air handling unit (AHU)\n",
    "- 2 sensors\n",
    "- 4 walls\n",
    "- 1 aggregation of three parts\n",
    "\n",
    "Let's start with the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N35a4bcc94cdb4a379976506b3995a230 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add space 1\n",
    "s = INST[\"space_1\"]\n",
    "p = RDF.type\n",
    "o = MFI[\"Space\"]\n",
    "g.add((s, p, o))\n",
    "# Add a simple name\n",
    "g.add((s, MFI.name, Literal(\"This is our first space.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N35a4bcc94cdb4a379976506b3995a230 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add space 2\n",
    "s = INST[\"space_2\"]\n",
    "p = RDF.type\n",
    "o = MFI[\"Space\"]\n",
    "g.add((s, p, o))\n",
    "# Add a simple name\n",
    "g.add((s, MFI.name, Literal(\"This is our second space.\")))\n",
    "\n",
    "# Add space 3\n",
    "g.add((INST[\"space_3\"], RDF.type, MFI[\"Space\"]))\n",
    "g.add((INST[\"space_3\"], MFI.name, Literal(\"This is our third space.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add also the other components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N35a4bcc94cdb4a379976506b3995a230 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 air handling unit (AHU)\n",
    "g.add((INST[\"AHU_45\"], RDF.type, MFI[\"AirHandlingUnit\"]))\n",
    "g.add((INST[\"AHU_45\"], MFI.name, Literal(\"The AirHandlingUnit.\")))\n",
    "\n",
    "# 2 sensors\n",
    "g.add((INST[\"TemperatureSensor_1\"], RDF.type, MFI[\"Sensor\"]))\n",
    "g.add((INST[\"TemperatureSensor_1\"], MFI.name, Literal(\"The sensor that measures temperature values.\")))\n",
    "\n",
    "g.add((INST[\"HumiditySensor_1\"], RDF.type, MFI[\"Sensor\"]))\n",
    "g.add((INST[\"HumiditySensor_1\"], MFI.name, Literal(\"The sensor that measures air humidity values.\")))\n",
    "\n",
    "# 4 walls\n",
    "g.add((INST[\"Wall_1\"], RDF.type, MFI[\"Wall\"]))\n",
    "g.add((INST[\"Wall_1\"], MFI.name, Literal(\"Wall number 1.\")))\n",
    "\n",
    "g.add((INST[\"Wall_2\"], RDF.type, MFI[\"Wall\"]))\n",
    "g.add((INST[\"Wall_2\"], MFI.name, Literal(\"Wall number 2.\")))\n",
    "\n",
    "g.add((INST[\"Wall_3\"], RDF.type, MFI[\"Wall\"]))\n",
    "g.add((INST[\"Wall_3\"], MFI.name, Literal(\"Wall number 3.\")))\n",
    "\n",
    "g.add((INST[\"Wall_4\"], RDF.type, MFI[\"Wall\"]))\n",
    "g.add((INST[\"Wall_4\"], MFI.name, Literal(\"Wall number 4.\")))\n",
    "\n",
    "# 1 aggregation of three parts\n",
    "g.add((INST[\"Aggregation_1\"], RDF.type, MFI[\"Aggregate\"]))\n",
    "g.add((INST[\"Aggregation_1\"], MFI.name, Literal(\"Note that aggregations should be modelled differently.\")))\n",
    "\n",
    "g.add((INST[\"Part_1\"], RDF.type, MFI[\"Part\"]))\n",
    "g.add((INST[\"Part_1\"], MFI.name, Literal(\"Part 1 of the aggregation.\")))\n",
    "\n",
    "g.add((INST[\"Part_2\"], RDF.type, MFI[\"Part\"]))\n",
    "g.add((INST[\"Part_2\"], MFI.name, Literal(\"Part 2 of the aggregation.\")))\n",
    "\n",
    "g.add((INST[\"Part_3\"], RDF.type, MFI[\"Part\"]))\n",
    "g.add((INST[\"Part_3\"], MFI.name, Literal(\"Part 3 of the aggregation.\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect our results\n",
    "Let's see what we created until now. We have a number of instances of different classes, let's see how many statements are now in our instance graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to print the statements in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Part_3'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Part'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_1'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Wall number 1.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#space_2'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Space'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#space_3'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Space'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#space_3'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('This is our third space.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_2'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Wall number 2.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_1'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Wall'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Aggregation_1'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Aggregate'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Part_1'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Part'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Part_2'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Part'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_4'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Wall number 4.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Part_1'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Part 1 of the aggregation.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_3'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Wall'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#space_1'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Space'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Part_3'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Part 3 of the aggregation.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_2'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Wall'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Aggregation_1'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Note that aggregations should be modelled differently.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_3'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Wall number 3.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#TemperatureSensor_1'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Sensor'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Part_2'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('Part 2 of the aggregation.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#HumiditySensor_1'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('The sensor that measures air humidity values.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('http://www.w3.org/2002/07/owl#Ontology'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#TemperatureSensor_1'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('The sensor that measures temperature values.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#space_2'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('This is our second space.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#HumiditySensor_1'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Sensor'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#space_1'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('This is our first space.'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#Wall_4'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#Wall'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#AHU_45'), rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'), rdflib.term.URIRef('https://example.org/myFirstOntology#AirHandlingUnit'))\n",
      "(rdflib.term.URIRef('https://example.org/myFirstInstanceGraph#AHU_45'), rdflib.term.URIRef('https://example.org/myFirstOntology#name'), rdflib.term.Literal('The AirHandlingUnit.'))\n",
      "\n",
      "We have the following number of statements:\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for stmt in g:\n",
    "    print(stmt)\n",
    "\n",
    "print()\n",
    "print(\"We have the following number of statements:\")\n",
    "print(len(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sensors do we have? Let's query the RDF graph and find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these sensors: \n",
      "https://example.org/myFirstInstanceGraph#TemperatureSensor_1\n",
      "https://example.org/myFirstInstanceGraph#HumiditySensor_1\n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?sensor\n",
    "WHERE{ ?sensor rdf:type mfi:Sensor }\"\"\"\n",
    "\n",
    "qres = g.query(ourQuery)\n",
    "\n",
    "print( \"Found these sensors: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.sensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now would be a good moment to store the result in a file and examine the graph in [OntoText GraphDB](https://www.ontotext.com/products/graphdb/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output/OurHouse.ttl in folder:\n",
      "/Users/stefan/Repositories/FireBIM/SSolDAC2024/handson-querying-and-interaction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "g.serialize(destination = \"output/OurHouse.ttl\", format = \"turtle\")\n",
    "print(\"Created output/OurHouse.ttl in folder:\")\n",
    "print(str(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have found our two sensors, let's try to see whether they are also recognized as `Elements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these elements: \n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?element\n",
    "WHERE{ ?element rdf:type mfi:Element }\"\"\"\n",
    "\n",
    "qres = g.query(ourQuery)\n",
    "\n",
    "print( \"Found these elements: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `Elements` are found, why is that? How many Elements should we have in our graph? Can you check in GraphDB?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding the ontology and making inferences\n",
    "Correct! We actually are not using the ontology that we created earlier! Our ontology is not published online, so the only way to use this ontology, is by loading it into our graph from the file that we created, and using it as such. So let's add our ontology first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new separate graph and load the ontology\n",
    "ontology_graph = Graph()\n",
    "ontology_graph.parse(\"output/myFirstOntology.ttl\")\n",
    "\n",
    "# Combine the graphs\n",
    "combined_graph = ontology_graph + g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not enough to solve our problem. While we now have a combined graph with all information (Abox + TBox), we do not have any inferred data still. To be able to include inferences, we need to include an inference engine. This can be done by loading the `owlrl` module (install it again if not available using `pip install owlrl`). In the below example, we import `owlrl` and make a deductive closure that includes `RDFS` semantics, one of the most basic inference schemes. Other deductive closures can be created as well, to include more complex inferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an inference engine\n",
    "import owlrl\n",
    "rdfs = owlrl.DeductiveClosure(owlrl.RDFS_Semantics)\n",
    "\n",
    "# Expand the combined graph\n",
    "rdfs.expand(combined_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our query again, and see if we can find all available elements according to the parent-child relationships that were included in the ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these elements: \n",
      "https://example.org/myFirstInstanceGraph#Aggregation_1\n",
      "https://example.org/myFirstInstanceGraph#Wall_1\n",
      "https://example.org/myFirstInstanceGraph#Wall_3\n",
      "https://example.org/myFirstInstanceGraph#Wall_4\n",
      "https://example.org/myFirstInstanceGraph#HumiditySensor_1\n",
      "https://example.org/myFirstInstanceGraph#Wall_2\n",
      "https://example.org/myFirstInstanceGraph#TemperatureSensor_1\n",
      "https://example.org/myFirstInstanceGraph#AHU_45\n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?element\n",
    "WHERE{ ?element rdf:type mfi:Element }\"\"\"\n",
    "\n",
    "qres = combined_graph.query(ourQuery)\n",
    "\n",
    "print( \"Found these elements: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding the needed relations\n",
    "While we now have the ontology and ABox instance graph combined, we never created any relations. Therefore, we don't know which elements are in which spaces, for example. Moreover, we don't even have any `hasPart` relations between the `Aggregation` and its `Parts`! Let's add the relations that we need between our instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding relations to the original ABox graph (without the ontology)\n",
    "g.add((INST[\"Aggregation_1\"], MFI.hasPart, INST[\"Part_1\"]))\n",
    "g.add((INST[\"Aggregation_1\"], MFI.hasPart, INST[\"Part_2\"]))\n",
    "g.add((INST[\"Aggregation_1\"], MFI.hasPart, INST[\"Part_3\"]))\n",
    "\n",
    "# for query and inference purposes, we combine our instance graph with the ontology graph again, and overwrite the combined_graph variable\n",
    "combined_graph = ontology_graph + g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregate should now be related to its parts. Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these aggregate-part relations: \n",
      "https://example.org/myFirstInstanceGraph#Aggregation_1 has part: https://example.org/myFirstInstanceGraph#Part_3\n",
      "https://example.org/myFirstInstanceGraph#Aggregation_1 has part: https://example.org/myFirstInstanceGraph#Part_2\n",
      "https://example.org/myFirstInstanceGraph#Aggregation_1 has part: https://example.org/myFirstInstanceGraph#Part_1\n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?aggregate ?part\n",
    "WHERE{ ?aggregate mfi:hasPart ?part }\"\"\"\n",
    "\n",
    "qres = combined_graph.query(ourQuery)\n",
    "\n",
    "print( \"Found these aggregate-part relations: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.aggregate} has part: {row.part}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we now have added statements to our combined graph, but we did not run the inference engine anew. New inference may be available at such a moment, and it makes sense to run this inference engine again. We will not do this now.\n",
    "\n",
    "Instead, we add all of our other remaining elements in some of the spaces that we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add((INST[\"Aggregation_1\"], MFI.hasLocation, INST[\"Space_1\"]))\n",
    "g.add((INST[\"Wall_1\"], MFI.hasLocation, INST[\"Space_2\"]))\n",
    "g.add((INST[\"Wall_2\"], MFI.hasLocation, INST[\"Space_2\"]))\n",
    "g.add((INST[\"Wall_3\"], MFI.hasLocation, INST[\"Space_2\"]))\n",
    "g.add((INST[\"Wall_4\"], MFI.hasLocation, INST[\"Space_2\"]))\n",
    "g.add((INST[\"HumiditySensor_1\"], MFI.hasLocation, INST[\"Space_3\"]))\n",
    "g.add((INST[\"TemperatureSensor_1\"], MFI.hasLocation, INST[\"Space_3\"]))\n",
    "g.add((INST[\"AHU_45\"], MFI.hasLocation, INST[\"Space_1\"]))\n",
    "\n",
    "# for query and inference purposes, we combine our instance graph with the ontology graph again, and overwrite the combined_graph variable\n",
    "combined_graph = ontology_graph + g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our elements assigned to the available spaces, let's see if we can query which elements are in each space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These elements are in the following spaces: \n",
      "https://example.org/myFirstInstanceGraph#AHU_45 is in space: https://example.org/myFirstInstanceGraph#Space_1\n",
      "https://example.org/myFirstInstanceGraph#Aggregation_1 is in space: https://example.org/myFirstInstanceGraph#Space_1\n",
      "https://example.org/myFirstInstanceGraph#HumiditySensor_1 is in space: https://example.org/myFirstInstanceGraph#Space_3\n",
      "https://example.org/myFirstInstanceGraph#TemperatureSensor_1 is in space: https://example.org/myFirstInstanceGraph#Space_3\n",
      "https://example.org/myFirstInstanceGraph#Wall_2 is in space: https://example.org/myFirstInstanceGraph#Space_2\n",
      "https://example.org/myFirstInstanceGraph#Wall_1 is in space: https://example.org/myFirstInstanceGraph#Space_2\n",
      "https://example.org/myFirstInstanceGraph#Wall_3 is in space: https://example.org/myFirstInstanceGraph#Space_2\n",
      "https://example.org/myFirstInstanceGraph#Wall_4 is in space: https://example.org/myFirstInstanceGraph#Space_2\n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?element ?space\n",
    "WHERE{ ?element mfi:hasLocation ?space }\"\"\"\n",
    "\n",
    "qres = combined_graph.query(ourQuery)\n",
    "\n",
    "print( \"These elements are in the following spaces: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.element} is in space: {row.space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also indicated in our ontology that the `hasLocation` property is the inverse of the `hasElement` property. Let's see if we can query which elements are in which space using this inverse relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spaces have the following elements: \n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?space ?element\n",
    "WHERE{ ?space mfi:hasElement ?element }\"\"\"\n",
    "\n",
    "qres = combined_graph.query(ourQuery)\n",
    "\n",
    "print( \"The spaces have the following elements: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.space} has element: {row.element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing indeed, we need to first rerun the correct inference engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdfs.expand(combined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spaces have the following elements: \n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?space ?element\n",
    "WHERE{ ?space mfi:hasElement ?element }\"\"\"\n",
    "\n",
    "qres = combined_graph.query(ourQuery)\n",
    "\n",
    "print( \"The spaces have the following elements: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.space} has element: {row.element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even by re-running our RDFS inference engine, we do not have the inverse relations included. This is because this RDFS inference engine excludes `inverseOf` relations. We need a more powerful inference engine to be able to include this. If you want to know more about this, then look into this documentation: https://owl-rl.readthedocs.io/en/latest/OWLRL.html.\n",
    "\n",
    "In our case, we will use the `OWLRL_Semantics` rather than the `RDFS_Semantics` inference settings (`DeductiveClosure`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "owlrlsem = owlrl.DeductiveClosure(owlrl.OWLRL_Semantics)\n",
    "\n",
    "# Expand the combined graph\n",
    "owlrlsem.expand(combined_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our query executes correctly this time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spaces have the following elements: \n",
      "https://example.org/myFirstInstanceGraph#Space_2 has element: https://example.org/myFirstInstanceGraph#Wall_1\n",
      "https://example.org/myFirstInstanceGraph#Space_3 has element: https://example.org/myFirstInstanceGraph#HumiditySensor_1\n",
      "https://example.org/myFirstInstanceGraph#Space_3 has element: https://example.org/myFirstInstanceGraph#TemperatureSensor_1\n",
      "https://example.org/myFirstInstanceGraph#Space_2 has element: https://example.org/myFirstInstanceGraph#Wall_2\n",
      "https://example.org/myFirstInstanceGraph#Space_2 has element: https://example.org/myFirstInstanceGraph#Wall_4\n",
      "https://example.org/myFirstInstanceGraph#Space_2 has element: https://example.org/myFirstInstanceGraph#Wall_3\n",
      "https://example.org/myFirstInstanceGraph#Space_1 has element: https://example.org/myFirstInstanceGraph#Aggregation_1\n",
      "https://example.org/myFirstInstanceGraph#Space_1 has element: https://example.org/myFirstInstanceGraph#AHU_45\n"
     ]
    }
   ],
   "source": [
    "ourQuery = \"\"\"PREFIX mfi: <https://example.org/myFirstOntology#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?space ?element\n",
    "WHERE{ ?space mfi:hasElement ?element }\"\"\"\n",
    "\n",
    "qres = combined_graph.query(ourQuery)\n",
    "\n",
    "print( \"The spaces have the following elements: \" )\n",
    "for row in qres:\n",
    "    print(f\"{row.space} has element: {row.element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!!! That is amazing. Let's write everything to a file and proceed to the next exercise.\n",
    "\n",
    "Be careful, we should always try to make an effort to only output the instance graph, and NOT the combined graph. The ontology is namely supposed to be stored publicly online, and not be included in every other instance graph. In the below example, we thus serialize only the ABox instance graph.\n",
    "\n",
    "Inspect the result in a Notepad environment, as well as in Ontotext GraphDB. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output/myFirstAboxGraph.ttl in folder:\n",
      "/Users/stefan/Repositories/FireBIM/SSolDAC2024/handson-querying-and-interaction\n"
     ]
    }
   ],
   "source": [
    "g.serialize(destination=\"output/myFirstAboxGraph.ttl\", format=\"turtle\")\n",
    "print(\"Created output/myFirstAboxGraph.ttl in folder:\")\n",
    "print(str(os.getcwd()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
